const { 
  buildCompleteFileTree, 
  calculateTreeDepth, 
  countFolders,
  findCircularDependencies,
  findUnusedExports,
  findDuplicateImports
} = require('../utils/fileTreeBuilder');

class WorkflowGeneratorService {
  /**
   * ì§„í–‰ìƒí™© ì „ì†¡
   */
  sendProgress(sessionId, phase, progress, details = {}) {
    if (sessionId && global.analysisEmitter) {
      global.analysisEmitter.emit(sessionId, {
        phase,
        progress,
        timestamp: new Date().toISOString(),
        ...details
      });
    }
  }

  /**
   * ì „ì²´ ì›Œí¬í”Œë¡œìš° ë¶„ì„ ìˆ˜í–‰
   */
  async analyzeWorkflow(projectData, fileAnalysisService, codeAnalysisService) {
    const { projectName, fileCount, totalSize, files, sessionId } = projectData;
    
    console.log('ðŸ“Š Backend analysis request:', { projectName, fileCount, totalSize });
    
    // 1ë‹¨ê³„: ì „ì²´ í´ë” êµ¬ì¡° ì™„ì „ ë§¤í•‘
    this.sendProgress(sessionId, 'íŒŒì¼ êµ¬ì¡° ë¶„ì„', 0.1, { status: 'í´ë” êµ¬ì¡° ë§¤í•‘ ì¤‘...' });
    const completeFileTree = buildCompleteFileTree(files);
    const treeDepth = calculateTreeDepth(completeFileTree);
    const totalFolders = countFolders(completeFileTree);
    
    console.log('ðŸŒ² Complete file tree built:', {
      totalFiles: files.length,
      treeDepth,
      totalFolders
    });
    
    this.sendProgress(sessionId, 'íŒŒì¼ êµ¬ì¡° ë¶„ì„', 0.2, { 
      status: 'í´ë” êµ¬ì¡° ë§¤í•‘ ì™„ë£Œ',
      totalFiles: files.length,
      treeDepth,
      totalFolders
    });
    
    // 2ë‹¨ê³„: íŒŒì¼ ë¶„ì„
    this.sendProgress(sessionId, 'íŒŒì¼ ë¶„ì„', 0.3, { status: 'íŒŒì¼ ìœ í˜• ë¶„ì„ ì¤‘...' });
    const fileAnalysis = fileAnalysisService.analyzeFiles(files);
    
    // 3ë‹¨ê³„: ì˜¤ë¥˜ ë° ê²½ê³  ê°ì§€
    this.sendProgress(sessionId, 'ì½”ë“œ ë¶„ì„', 0.4, { status: 'ì½”ë“œ ì´ìŠˆ ê²€ì‚¬ ì¤‘...' });
    const errors = [];
    const warnings = [];
    
    if (files && Array.isArray(files)) {
      files.forEach(file => {
        const { errors: fileErrors, warnings: fileWarnings } = codeAnalysisService.detectIssuesInFile(file);
        errors.push(...fileErrors);
        warnings.push(...fileWarnings);
      });
    }
    
    // TypeScript ì˜¤ë¥˜ ì¶”ê°€ (ì˜µì…˜)
    try {
      const tsErrors = await fileAnalysisService.checkTypeScriptErrors();
      errors.push(...tsErrors);
    } catch (error) {
      console.warn('TypeScript ê²€ì‚¬ ì‹¤íŒ¨:', error.message);
    }
    
    // 4ë‹¨ê³„: Import/Export ê´€ê³„ ë¶„ì„
    this.sendProgress(sessionId, 'Import ë¶„ì„', 0.5, { status: 'Import ê´€ê³„ ë¶„ì„ ì¤‘...' });
    const importConnections = codeAnalysisService.analyzeImports(files);
    
    // 5ë‹¨ê³„: API í˜¸ì¶œ ë¶„ì„
    this.sendProgress(sessionId, 'API ë¶„ì„', 0.6, { status: 'API í˜¸ì¶œ ë¶„ì„ ì¤‘...' });
    const apiConnections = codeAnalysisService.analyzeApiCalls(files);
    
    // 6ë‹¨ê³„: ì—°ê²° ê´€ê³„ ì¢…í•© ë¶„ì„
    this.sendProgress(sessionId, 'ì¢…í•© ë¶„ì„', 0.8, { status: 'ì—°ê²° ê´€ê³„ ì¢…í•© ë¶„ì„ ì¤‘...' });
    const connectionAnalysis = {
      totalConnections: importConnections.length + apiConnections.length,
      validConnections: [...importConnections, ...apiConnections].filter(c => c.status === 'success').length,
      warningConnections: [...importConnections, ...apiConnections].filter(c => c.hasWarning).length,
      errorConnections: [...importConnections, ...apiConnections].filter(c => c.hasError).length,
      circularDependencies: findCircularDependencies(importConnections),
      unusedExports: findUnusedExports(files, importConnections),
      duplicateImports: findDuplicateImports(importConnections),
      brokenLinks: [...importConnections, ...apiConnections].filter(c => c.hasError || c.status === 'error')
    };
    
    // ì‹¤ì œ íŒŒì¼ ì •ë³´ ìƒì„±
    const realFiles = files.map((file, index) => ({
      id: index,
      name: file.name,
      path: file.path,
      type: file.type || file.name.split('.').pop()?.toLowerCase() || '',
      size: file.size,
      hasErrors: errors.some(e => e.file === file.name || e.path === file.path),
      hasWarnings: warnings.some(w => w.file === file.name || w.path === file.path)
    }));
    
    this.sendProgress(sessionId, 'ë¶„ì„ ì™„ë£Œ', 1.0, { status: 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.' });
    
    // ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return {
      projectName,
      completeFileTree,
      connectionAnalysis,
      totalFiles: fileCount || 0,
      totalSize: totalSize || 0,
      languages: fileAnalysis.languages,
      frameworks: fileAnalysis.frameworks,
      topDirectories: fileAnalysis.topDirectories,
      largeFiles: fileAnalysis.largeFiles,
      errors: errors,
      warnings: warnings,
      errorCount: errors.length,
      warningCount: warnings.length,
      hasIssues: errors.length > 0 || warnings.length > 0,
      analyzedAt: new Date().toISOString(),
      isRealAnalysis: !!files,
      realFiles: realFiles,
      importConnections: importConnections,
      apiConnections: apiConnections
    };
  }

  /**
   * ì˜ì¡´ì„± ë¶„ì„
   */
  async analyzeDependencies(filePaths, codeAnalysisService) {
    const dependencies = {};
    const fs = require('fs').promises;
    
    for (const filePath of filePaths) {
      try {
        const content = await fs.readFile(filePath, 'utf-8');
        const imports = codeAnalysisService.extractImports(content, filePath);
        const exports = codeAnalysisService.extractExports(content, filePath);
        
        dependencies[filePath] = {
          imports,
          exports,
          path: filePath,
          name: require('path').basename(filePath)
        };
      } catch (error) {
        console.error(`Error analyzing ${filePath}:`, error);
        dependencies[filePath] = {
          error: error.message,
          imports: [],
          exports: []
        };
      }
    }
    
    return dependencies;
  }

  /**
   * ìˆœí™˜ ì°¸ì¡° ê°ì§€
   */
  detectCircularDependencies(dependencies) {
    const { resolveImportPathWithFS } = require('../utils/importResolver');
    const graph = {};
    
    Object.keys(dependencies).forEach(file => {
      graph[file] = dependencies[file].imports
        .map(imp => resolveImportPathWithFS(imp.source, file))
        .filter(path => path && dependencies[path]);
    });

    // DFSë¡œ ìˆœí™˜ ì°¸ì¡° ì°¾ê¸°
    const cycles = [];
    const visited = new Set();
    const recursionStack = new Set();

    function dfs(node, path = []) {
      if (recursionStack.has(node)) {
        const cycleStart = path.indexOf(node);
        const cycle = path.slice(cycleStart).concat(node);
        cycles.push(cycle);
        return;
      }

      if (visited.has(node)) return;

      visited.add(node);
      recursionStack.add(node);
      path.push(node);

      const neighbors = graph[node] || [];
      neighbors.forEach(neighbor => {
        dfs(neighbor, [...path]);
      });

      recursionStack.delete(node);
    }

    Object.keys(graph).forEach(node => {
      if (!visited.has(node)) {
        dfs(node);
      }
    });

    // ì¤‘ë³µ ì œê±°
    return cycles.filter((c, i, arr) => 
      i === arr.findIndex(cycle => 
        cycle.join(',') === c.join(',')
      )
    );
  }

  /**
   * API ë§¤ì¹­
   */
  matchAPIs(backend, frontend) {
    const { pathsMatch } = require('../utils/apiContractValidator');
    const matches = {
      matched: [],
      unmatched: {
        backend: [],
        frontend: []
      }
    };
    
    // REST API ë§¤ì¹­
    const backendREST = backend.filter(e => e.type === 'rest');
    const frontendREST = frontend.filter(e => e.type === 'rest');
    
    backendREST.forEach(be => {
      const found = frontendREST.find(fe => 
        fe.method === be.method && 
        pathsMatch(be.path, fe.path)
      );
      
      if (found) {
        matches.matched.push({
          backend: be,
          frontend: found
        });
      } else {
        matches.unmatched.backend.push(be);
      }
    });
    
    frontendREST.forEach(fe => {
      const found = backendREST.find(be => 
        be.method === fe.method && 
        pathsMatch(be.path, fe.path)
      );
      
      if (!found) {
        matches.unmatched.frontend.push(fe);
      }
    });
    
    // WebSocket ì´ë²¤íŠ¸ ë§¤ì¹­
    const backendWS = backend.filter(e => e.type === 'websocket');
    const frontendWS = frontend.filter(e => e.type === 'websocket');
    
    backendWS.forEach(be => {
      const found = frontendWS.find(fe => 
        be.path === fe.path && 
        ((be.method === 'WS_IN' && fe.method === 'WS_OUT') ||
         (be.method === 'WS_OUT' && fe.method === 'WS_IN'))
      );
      
      if (found) {
        matches.matched.push({
          backend: be,
          frontend: found
        });
      } else {
        matches.unmatched.backend.push(be);
      }
    });
    
    return matches;
  }
}

module.exports = WorkflowGeneratorService;